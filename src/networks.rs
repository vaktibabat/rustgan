// This first import is only used in debug mode
use std::{fs::File, io::Write};
use crate::neural_net::{Loss, NeuralNet};
use ndarray::{Array1, Array2, ArrayView2, Axis};
use rand::{thread_rng, Rng};
use rand_distr::{Distribution, Normal};

const NOISE_DIM: usize = 100;
const IMAGE_SIZE: usize = 28;

// Helper trait on Array2 in order to sample random batches from the dataset
// and to sample noise from the dataset
trait SampleRandom {
    // Sample m random rows from this matrix
    fn random_sample(&self, m: usize) -> Self;
    // Sample m random gaussian noise vectors each of dimension n
    fn noise_sample(m: usize, n: usize) -> Self;
}

impl SampleRandom for Array2<f64> {
    fn random_sample(&self, m: usize) -> Self {
        let mut rng = thread_rng();
        let mut idxs = vec![];
        let mut sample = Array2::zeros((0, self.ncols()));

        // Generate the random indexes
        for _ in 0..m {
            idxs.push(rng.gen_range(0..self.nrows()));
        }
        // Push the corresponding rows to a new matrix
        for idx in idxs {
            let row = self.row(idx);
            sample.push_row(row).unwrap();
        }

        sample
    }

    fn noise_sample(m: usize, n: usize) -> Self {
        let dist = Normal::new(0f64, 1f64).unwrap();
        let mut rng = thread_rng();
        let noise = Array2::from_shape_fn((m, n), |_| dist.sample(&mut rng));

        noise
    }
}

//-----------------START NETWORK TYPES---------------------
pub struct FullyConnected {
    net: NeuralNet,
}

pub struct GenerativeAdverserial {
    pub discriminator: NeuralNet,
    pub generator: NeuralNet,
    // The user can specify a path to save the intermediate images
    // generated by the model if they want to
    img_path: Option<String>,
    // Whether to print intermediate losses
    print_losses: bool
}
//-----------------END NETWORK TYPES-----------------------
//-----------------START FULLY CONNECTED-------------------
impl FullyConnected {
    pub fn new(
        num_epochs: usize,
        batch_size: usize,
        learning_rate: f64,
        loss: Loss,
    ) -> FullyConnected {
        let net = NeuralNet::new(num_epochs, batch_size, learning_rate, loss);

        FullyConnected { net }
    }

    // Compute the gradient of this network's loss (MSE/Cross Entropy) WRT the output
    fn upstream_loss(
        loss: Loss,
        net_out: &Array2<f64>,
        ground_truth: &ArrayView2<f64>,
    ) -> Result<Array2<f64>, ()> {
        match loss {
            Loss::Mse => {
                // Number of elements in the GT
                let m = ground_truth.ncols() as f64;

                Ok((2f64 / m) * (net_out - ground_truth))
            }
            Loss::CrossEntropy => Ok(net_out - ground_truth),
            _ => {
                // GAN loss types are unimplemented for a FCN
                Err(())
            }
        }
    }
}

impl FullyConnected {
    pub fn fit(&mut self, x: Array2<f64>, y: Array2<f64>) {
        // Extract training hyperparameters
        let num_epochs = self.net.num_epochs();
        let learning_rate = self.net.learning_rate();
        let batch_size = self.net.batch_size();
        let loss = self.net.loss();
        let net = &mut self.net;

        // Training loop
        for num_epoch in 0..num_epochs {
            for (input_batch, gt_batch) in x
                .axis_chunks_iter(Axis(0), batch_size)
                .zip(y.axis_chunks_iter(Axis(0), batch_size))
            {
                // Compute the forward pass on the input batch
                net.forward(&input_batch.view(), true);
                // Compute the gradients using the backward pass
                let net_out = &net.cache_last();
                let dy = FullyConnected::upstream_loss(loss, net_out, &gt_batch).unwrap();
                let mut gradients = net.backward(dy).0;
                gradients.reverse();
                // Perform GD step
                for i in 0..net.layers.len() {
                    // The current gradient
                    let grad = &gradients[i];

                    // Proceed only if there are parameter gradients
                    // layers such as ReLU don't have any parameters, so we don't need to update anything
                    if let (Some(dw), Some(db)) = grad {
                        net.layers[i].update_params(&dw, &db, learning_rate);
                    }
                }
            }

            println!("Finished epoch {}", num_epoch);

            // Print our current loss
        }
    }

    fn predict(&mut self, x: Array2<f64>) -> Array2<f64> {
        let net = &mut self.net;

        // For FCN, the prediction is just the output of the net
        net.forward(&x.view(), false)
    }
}
//-------------------END FULLY CONNECTED--------------
//-------------------START GAN------------------------
impl GenerativeAdverserial {
    // The upstream gradient of the Discriminator's loss WRT the discriminator's output on
    // a batch containing generated samples and real samples
    fn upstream_disc(net_out: &Array2<f64>) -> Array2<f64> {
        // The first half of the outputs are probabilities for real training samples
        // The other half are probabilities for samples generated from noise by the generator
        let m = net_out.nrows() / 2;
        let mut out_grad = Array2::zeros((0, 1));

        // The upper half
        for i in 0..m {
            let prob_xi = net_out.row(i)[0];
            // Derivative of log(D(x_i)) WRT D(x_i) is 1 / D(x_i)
            let dprob_xi = 1f64 / prob_xi;
            let to_push = Array1::from_elem(1, dprob_xi);
            out_grad.push_row(to_push.view()).unwrap();
        }
        // The lower half
        for i in m..2 * m {
            let prob_gzi = net_out.row(i)[0];
            // Derivative of log(1 - D(G(z_i))) WRT D(G(z_i)) is 1 / (D(G(z_i)) - 1)
            let dprob_gzi = 1f64 / (prob_gzi - 1f64);
            let to_push = Array1::from_elem(1, dprob_gzi);
            out_grad.push_row(to_push.view()).unwrap();
        }

        -1f64 * (1f64 / m as f64) * out_grad
    }

    // The gradient of the Generator's loss WRT each pixel in each image
    // in the generator's batch
    fn upstream_gen(
        net_out: &Array2<f64>,
        disc_out: &Array2<f64>,
        dy_dgzi: &Array2<f64>,
    ) -> Array2<f64> {
        // net_out contains the generated images, of shape (batch_size, img_size)
        let m = net_out.nrows();
        // The gradient of the loss WRT each pixel in each output image
        // shape: (batch_size, img_size)
        let mut out_grad = Array2::zeros((0, IMAGE_SIZE*IMAGE_SIZE));

        // Compute the gradients
        for i in 0..m {
            let prob_gzi = disc_out.row(i)[0];
            // Derivative of log(D(G(z_i))) WRT D((G(z_i))) is 1 / D(G(z_i)))
            let dprob_gzi = 1f64 / prob_gzi;
            // The gradient of the loss WRT counterfeit i
            let dy_curr = dy_dgzi.row(i);
            let to_push = dy_curr.map(|x| x * dprob_gzi);
            out_grad.push_row(to_push.view()).unwrap();
        }

        (1f64 / m as f64) * out_grad
    }

    // The loss of the discriminator on some input batch composed of real and generated samples
    // the first batch_size samples are real, while the rest are counterfeit
    fn disc_loss(net_out: &Array2<f64>) -> f64 {
        let m = net_out.nrows() / 2;
        let real_range: Vec<usize> = (0..m).collect();
        let fake_range: Vec<usize> = (m..2*m).collect();
        let real_samples = net_out.select(Axis(0), &real_range);
        let fake_samples = net_out.select(Axis(0), &fake_range);

        // We take the sum of the logs of the predicted probabilties of each real sample
        // plus the sum of the logs of the complement of the predicted probabilities for each fake sample
        let loss = real_samples.map(|x| x.log2()).sum() +
               fake_samples.map(|x| (1f64 - x).log2()).sum();

        (1f64 / m as f64) * loss
    }

    // The loss of the generator 
    fn gen_loss(net_out: &Array2<f64>) -> f64 {
        let m = net_out.nrows();
        let fake_range: Vec<usize> = (0..m).collect();
        let fake_samples = net_out.select(Axis(0), &fake_range);
        let loss = fake_samples.map(|x| x.log2()).sum();

        (1f64 / m as f64) * loss
    }
}

impl GenerativeAdverserial {
    // When we fit a GAN, we only need a list of images
    // so there aren't any GT
    pub fn fit(&mut self, x: Array2<f64>) {
        // Extract training hyperparameters
        let num_epochs = self.discriminator.num_epochs();
        let learning_rate = self.discriminator.learning_rate();
        let batch_size = self.discriminator.batch_size();
        let disc = &mut self.discriminator;
        let gen = &mut self.generator;
        let batches_per_epoch = x.nrows() / batch_size;
        let mut losses_file = match self.print_losses {
            true => Some(File::create("./losses.txt").unwrap()),
            false => None,
        };

        for num_epoch in 0..num_epochs {
            for _ in 0..batches_per_epoch {
                // Begin discriminator training step
                // Sample minibatch of m training samples
                let mut input_batch = x.random_sample(batch_size);
                // Sample minibatch of m noise vectors, each of NOISE_DIM dimensions
                let noise_batch = Array2::noise_sample(batch_size, NOISE_DIM);
                let gen_samples = gen.forward(&noise_batch.view(), false);
                // Concatente them into one matrix, since we want the discriminator
                // to run both on the input and on the noise and produce probabilities for each sample
                input_batch.append(Axis(0), gen_samples.view()).unwrap();
                // Run the discriminator
                disc.forward(&input_batch.view(), true);
                // Get the gradients by running the backward pass
                let net_out = &disc.cache_last();
                let dy = GenerativeAdverserial::upstream_disc(net_out);
                let mut gradients = disc.backward(dy).0;
                gradients.reverse();
                // Perform a GD step on the discriminator
                for i in 0..disc.layers.len() {
                    // The current gradient
                    let grad = &gradients[i];

                    // Proceed only if there are parameter gradients
                    // layers such as ReLU don't have any parameters, so we don't need to update anything
                    if let (Some(dw), Some(db)) = grad {
                        disc.layers[i].update_params(&dw, &db, learning_rate);
                    }
                }
                // End discriminator training step
                // Begin generator training step
                // Sample minibatch of m noise vectors, each of NOISE_DIM dimensions
                let noise_batch = Array2::noise_sample(batch_size, NOISE_DIM);
                // Run the generator on the noise to generate new samples mimicing the training data
                let gen_samples = gen.forward(&noise_batch.view(), true);
                // Run the discriminator on the generated samples
                disc.forward(&gen_samples.view(), true);
                // The output of the discriminator on the generated images
                let disc_out = disc.cache_last().clone();
                // The first element in the discriminator's cache (the gradient of the discriminator)
                // WRT the generated samples
                // is used to compute the gradient of the generator
                let dy = GenerativeAdverserial::upstream_disc(&disc_out);
                let gen_grads = disc.backward(dy).1;
                // Get the gradient by running the backward pass
                let dy = GenerativeAdverserial::upstream_gen(&gen_samples, &disc_out, &gen_grads);
                let mut gradients = gen.backward(dy).0;
                gradients.reverse();
                // Perform a GD step on the generator
                for i in 0..gen.layers.len() {
                    // The current gradient
                    let grad = &gradients[i];

                    // Proceed only if there are parameter gradients
                    // layers such as ReLU don't have any parameters, so we don't need to update anything
                    if let (Some(dw), Some(db)) = grad {
                        gen.layers[i].update_params(&dw, &db, learning_rate);
                    }
                }
            }

            // Test discriminator on a random batch
            let noise_batch = Array2::noise_sample(batch_size, NOISE_DIM);
            let gen_samples = gen.forward(&noise_batch.view(), false);
            let mut input_batch = x.random_sample(batch_size);
            input_batch.append(Axis(0), gen_samples.view()).unwrap();
            let disc_out = disc.forward(&input_batch.view(), false);
            // Test the discriminator on the fake batch and use that to compute the generator loss
            let disc_out_fake = disc.forward(&gen_samples.view(), false);
            //let disc_res = disc.forward(&gen_samples.view(), false);
            if self.print_losses {
                let disc_loss = GenerativeAdverserial::disc_loss(&disc_out);
                let gen_loss = GenerativeAdverserial::gen_loss(&disc_out_fake);
                println!("Completed epoch {}", num_epoch);
                println!("Discriminator loss: {},", disc_loss);
                println!("Generator loss: {}", gen_loss);
                // Write them to a file
                losses_file.as_mut().unwrap().write_all(format!("{}\t{}\n", disc_loss, gen_loss).as_bytes()).unwrap();
            }

            if let Some(inter_img_path) = &self.img_path {
                // Write to disk
                let mut curr_file = File::create(format!("{}/{}", inter_img_path, num_epoch)).unwrap();
                

                for x in gen_samples.row(0) {
                    curr_file.write_all(format!("{},", x).as_bytes()).unwrap();
                }
            }
        }
    }

    pub fn generate(&mut self, x: Array2<f64>) -> Array2<f64> {
        self.generator.forward(&x.view(), false)
    }
}

impl GenerativeAdverserial {
    pub fn new(num_epochs: usize, batch_size: usize, learning_rate: f64, img_path: Option<String>) -> GenerativeAdverserial {
        let discriminator = NeuralNet::new(
            num_epochs,
            batch_size,
            learning_rate,
            Loss::GanDiscriminator,
        );
        let generator = NeuralNet::new(num_epochs, batch_size, learning_rate, Loss::GanGenerator);

        GenerativeAdverserial {
            discriminator,
            generator,
            img_path,
            print_losses: true
        }
    }
}
//---------------------END GAN---------------------------

#[cfg(test)]
mod tests {
    use ndarray::Array2;
    use rand::{
        distributions::{Distribution, Uniform},
        thread_rng,
    };

    use crate::layers::{Linear, ReLU};

    use super::FullyConnected;

    // Helper trait for generating random matrices
    trait RandomInit {
        fn random(n: usize, m: usize) -> Self;
    }

    impl RandomInit for Array2<f64> {
        fn random(n: usize, m: usize) -> Self {
            let mut rng = thread_rng();
            let dist = Uniform::new(-1f64, 1f64);
            // Create the weight matrix
            Array2::from_shape_fn((n, m), |_| dist.sample(&mut rng))
        }
    }

    #[test]
    fn test_fully_connected() {
        // Input data
        let x = Array2::random(20000, 1);
        // Linear transformation on x - the GT
        let y = x.map(|x| (x / 2f64) + x.exp()) + Array2::from_elem((20000, 1), 3.27);
        // Create our net - only one neuron
        let mut net = FullyConnected::new(3, 32, 0.003, crate::neural_net::Loss::Mse);
        net.net.add_layer(Box::new(Linear::new(1, 500)));
        net.net.add_layer(Box::new(ReLU::new()));
        net.net.add_layer(Box::new(Linear::new(500, 1)));
        // Train it
        net.fit(x, y.clone());
        // Print our weight values - should be w close to 1.337 and b close to 3.27
        println!("Finished training");
        let input_vec =
            Array2::from_shape_vec((200, 1), (-100..100).map(|x| (x as f64) / 100f64).collect())
                .unwrap();
        let output_vec = net.predict(input_vec.clone());
        let correct_vec = input_vec.map(|x| (x / 2f64) + x.exp() + 3.27);

        // TODO - change this to a more correct test
        // the function should be approximated, measuring the distance between each two outputs is not good
        // because outliers break it
        for (y, z) in correct_vec.iter().zip(output_vec.iter()) {
            assert!((y - z).abs() < 0.1);
        }
    }
}
